\section{The Voss Prover}

Although symbolic trajectory evaluation is a very successful
approach for verifying many realistic circuits, two weaknesses have been noted.

First, there can be a semantic gap between the
trajectory evaluation and what the user
has in mind. Part of the problem is that 
the proof is structured at the bit-level, when
it may be more natural to represent the proof in
terms of a higher-level domain (for example arguing
about integers rather than bit-vectors). And, 
unlike with theorem-proving, we cannot exploit
any form of structure to guide the proof.

Second, it is still computationally expensive and
approaches that reduce this cost are needed.
In particular, due to the underlying data representation
techniques used and the inability to decompose the
proof, there are some types of circuits which are in
practice unverifiable using this approach alone ---
for example a multiplier circuit.

Compositional approaches make the verification easier
for the user, particularly for very large systems.
Verifying the individual components separately is
much more efficient for a variety of reasons.  It
allows re-use of results and, most importantly, it
greatly reduces the state space of systems that need
to be explored.

STE lends itself to a compositional approach
because each verification takes place in the
context of the entire system. This means that
it is not necessary to decompose the next state function.
Further, it makes the theory of composition simpler
than other model-checking techniques. Using domain
knowledge (for example, properties of integers)
makes composition efficient and practical.

Moreover, a sound compositional theory does not
require that the same proof technique be used
throughout, a motivation for a hybrid method.
By hybrid methods, we mean the combined use of different
verification methods in a rigorous and sound way.
One of the first systems which combined different approaches
rigorously was the HOL-Voss system
\cite{SegerJoyce92,joyceseger93}, linking the HOL theorem-prover and
the Voss STE system.  This enables the proof of something
within one system to be carried over into the other
system. Although HOL-Voss is a much more powerful and
general system than the VossProver, it is not clear that all
the extra power is useful, and it is much more difficult
to learn to use.  Our system has the rules for
composing STE results built in.

Our approach uses STE to verify the individual 
components of the circuit automatically. A model
checking approach is often the most suitable here
because it relieves the human verifier of much
tedious work. We propose that the human verifier
concentrate on combining the lower level results
using theorem proving techniques.

Whereas STE is a purely
behavioural method, for our new theory to be useful,
it is important that some structure be readily
identifiable.  However, we are not moving to a purely
structural model since our method deals more with the
composition of the specification and the proof than
the composition of the underlying circuit. So
although we need to be able to use some structure in
our system, we have neither to build a structural
model of the system, nor describe the behaviour of
the component parts.  

An important lesson learned from theorem proving
is that assistance for the human verifier is
crucial. 
Perhaps the most important part of the utility of
these tools is the way in which they can interact
with the user. In HOL, for example, the user can
write proof scripts in ML. This programmability
alleviates some of the tedium of theorem proving and
makes the tool much more flexible. 

In our tool too, the user has a fully programmable
script language for writing proofs.
This facilitates proof management and allows
the user to build up the equivalent of
HOL tactics. Skilful human intervention is
critical, but this process can help manage
and guide the proof process and to build
up the proof in parts.

Automated proof steps can be very helpful in
reducing the load on the verifier. In our
system we provide some automated assistance
with decision procedures for integers. 
In addition, there is a simple auxiliary 
theorem prover for integers (the decision
procedures are limited). This auxiliary prover
and the decision procedures allow effective
use of domain knowledge.

Also important is the automatic assistance 
provided for composing STE results. Heuristic
routines ``guess'' a strategy, and the tool
then checks that the strategy is sound.

In the remaining parts of this section we discuss an early
version of the VossProver.
A complete re-write is currently underway and is expected to be
released in April 1995.
In general, the VossProver consists of a collection of FL programs
that, altogether, creates a ``theorem prover'' or ``proof assistant''
specialized for STE composition.


\subsection{Using the prover}

Verification results are stored as objects of type {\tt Theorem}.
There are three constituent parts of a theorem:
\begin{enumerate}
\item 
The most important part is an antecedent/consequent pair, representing
a trajectory assertion which has been proved to hold.  
Antecedents and consequents are trajectory formulas. 

\item
In some
proof steps, the prover has to rely on knowledge given
by the user. For example, the system may need to use
the fact that $x*(y+z) = xy+xz$. This sort of domain
knowldge can be provided by the user. The second component
of a theorem contains the assumptions on which the proof 
of the theorem relied.

\item
The third component is a boolean expression containing 
{\em mapping} information. For the moment assume this
boolean expression is the constant true. Later on we
discuss how this information can be used.
\end{enumerate}


\subsection{Using domain knowledge}


Some of the rules discussed below need to compare trajectories.
In comparing trajectories, the rules often need to know whether
two syntactically different objects are semantically the
same (e.g. is $x(y+z) = xy+xz$). Although the prover does 
try to normalise integer expressions into a canonical form,
there are still many semantically equivalent expressions which
normalise into different syntactic forms. Thus,
rhese procedures take a function of type {\tt proof\_type} which
performs these comparisons. 

The following procedures are
provided:

\begin{enumerate}
\item {\tt <::>}. This is the empty proof rule.  The system
only uses the normalisation routines. After that, if two objects
are syntactically different, they are treated as being inequivalent.

\item {\tt use\_only\_bdd}. To prove whether a boolean expression
(of type {\tt B}) holds, the system will convert to BDDs and
check for BDD equivalence.

\item {\tt use\_rules}. This is a function which takes a list
of facts. Whenever the system needs to compare two objects
it uses the facts provided in order to try to prove the
result.

To provide a fact for the system to use, construct an object
of type DomainResult. 

\begin{verbatim}
lettype DomainResult = Proof   B (DomainResult list) | 
                       Assume  B;
\end{verbatim}

Typically, this would be done using the Assume constructor
where the B objects used are of the form {\tt Nequal a b}.
For example,

\begin{verbatim}
let fact1 = Assume (Nequal (x*(y+z)) (x*y + x*x))
\end{verbatim}

Thus {\tt use\_rule [fact1]} is of type {\tt proof\_type}.


\item {\tt use\_rules\_then\_bdd}.  This is a function which takes a list
of facts. Whenever the system needs to compare two objects
it uses the facts provided in order to try to prove the
result. If none of the facts are useful, then the system
converts to BDDs.

\end{enumerate}

\subsubsection*{Writing your own prover}

The data declaration for {\tt proof\_type} is

\begin{verbatim}

new_type_abbrev proof_type = (B->bool)#(DomainResult list);

\end{verbatim}

The first element of the pair is the function which takes
a B expressions and determines whether it is a tautology.
The second element of the pair is the list of facts provided
by the user which the proof relies on (this is used for
printing out information for the user),


\subsection{Inference Rules}

\noindent
Theorems are  represented as triples. As for the moment
we are ignoring the mapping information, the first description
of the rules only use the theory, assertion pairs.


\begin{enumerate}

\item
Symbolic Trajectory Evaluation: {\tt VOSS varmap (A, C)}

Type: {\tt (bool list)->(traj\_tp\#traj\_tp)->Theorem}

The VOSS rule takes two arguments. The first is a BDD variable
ordering. The second is an antecedent, consequent pair. 
Symbolic trajectory evaluation is performed on the circuit
to check whether $\Assert{A}{C}$. If the trajectory evaluation
succeeds, then  $(\Assert{A}{C},\, [])$ is returned as a theorem
(note, the empty list means that the proof relies on no theory).

The BDD variable ordering is given as a list of bool variables.
The procedure {\tt autoN} of type {\tt N -> bool list} is a
heuristic which attempts to find a good variable ordering for
a given integer expression. {\tt autoB} is a similar procedure
for B expressions.

\item Identity: {\tt IDENTITY  t}

Type: {\tt traj\_tp->Theorem}

Takes a trajectory formula $t$ and returns the result
($\Assert{t}{t},\,[])$. This can be useful in starting up `induction'
style arguments.

\item Time shifting: {\tt SHIFT BaseThm  t}

Type: {\tt Theorem->int->Theorem}

Takes a theorem $(\Assert{A}{C},\, H)$ 
which has already been proved and time-shifts it
$t$ units, returning $\Assert{\N^tA}{\N^tC},\, H)$. 

\item Conjunction: {\tt CONJUNCT  Thm1 Thm2}

Type: {\tt Theorem->Theorem->Theorem}

Takes two theorems $(\Assert{A_1}{C_1},\, H_1)$ and 
$(\Assert{A_2}{C_2}, H_2)$ and applies the conjunction rule to
return $(\Assert{A_1\land A_2}{C_1\land C_2},\, H_1\cup H_2)$.

\item Specialisation: {\tt SPECIAL   Thm1  spec}

Type: {\tt Theorem->speclist->Theorem}

Given a theorem $(\Assert{A}{C},\, T)$ and a specialisation
$\sigma$, returns the theorem $(\Assert{\sigma(A)}{\sigma(C)},T)$.

A specialisation is a list of substitution-guard pairs. A
substitution has two components: a substitution list for 
boooleans and a substitution list for numbers. A substitution
list contains a list of string-expression pairs. The string 
is the name of a variable, and the expression is the value which
the variable is substituted with. The data structure is 
given below.

\begin{verbatim}

new_type_abbrev boolsublist = (string#B)  list;
new_type_abbrev intsublist  = (string#N)  list;
new_type_abbrev speclist = ((boolspeclist#intspeclist)#B) list;

\end{verbatim}


\item Rules of consequence:\\
{\tt PRESTRONG P Thm NewAnt\\
POSTWEAK  proof Thm NewCon}

Type: {\tt proof\_type->Theorem->traj\_tp->Theorem}

These rules implement precondition strengthening and postcondition
weakening. {\tt PRESTRONG} takes a proof procedure
$P$, a theorem $(\Assert{A}{C}, H)$ which has
already been proved, and a new candidate antecedent $A'$. It then
checks whether $\delta_A \order \delta_{A'}$. If it is, then
the new theorem $(\Assert{A'}{C},\, H')$ is returned. 
$H'$ is the new assumption list containing all the assumptions
of $H$ as well as any new assumptions introduced by $P$.

When checking
that $\delta_A \order \delta_{A'}$ the proof procedure $P$
may be used\footnote{Note, that the assummptions in $H$ are not used
automatically. If you want to use the rules that are in $T$ you
must supply them as part of $P$. The reason for this is
practical --- since these forms of comparisons can be costly
for some computations we want to provide the user with the
ability to choose which rules are used. It would be easy to 
automatically use the rules in $P$ but this might lead to much
useless computation. When providing theory information always
provide as little as necessary.}. {\tt POSTWEAK} is similar.

\item Transitivity: {\tt TRANS P Thm1 Thm2}

Type: {\tt proof\_type->Theorem->Theorem->Theorem}

Takes a proof procedure $P$, two 
theorems $(\Assert{A_1}{C_1}, H_1)$ and 
$(\Assert{A_2}{C_2}, H_2)$. It checks
whether $\delta_{A_2} \order {\delta_{A_1}}\sqcup{\delta_{C_1}}$.
In computing this the proof procedure is used. If the
comparison is successful, the theorem $(\Assert{A_1}{C_2}, H')$
where $H'$ is the list of all assumptions made in $H_1$, $H_2$
and by the procedure $P$.


\item Automatically Specialise/Transitivity: 
{\tt SPTRANS  P  Thm1 Thm2}

Type: {\tt proof\_type->Theorem->Theorem->Theorem}

Many proofs contain a step in which a user specialises 
one result and then uses the specialised result as one
of the arguments to the {\tt TRANS} rule. The {\tt SPTRANS}
rule tries to make this easier by automatically coming
up with the appropriate specialisation.

{\tt SPTRANS} rule takes a proof procedure $P$, and two theorems 
$(\Assert{A_1}{C_1}, H_1)$ and $(\Assert{A_2}{C_2}, H_2)$.
It applies a heuristic to these theorems to find a specialisation
$\sigma$ and then checks whether $\delta_{\sigma(A_2)}
\order {\delta_{A_1}}\sqcup{\delta_{C_1}}$ (it may use
the $P$ for this). If the comparison succeeds
then the theorem $(\Assert{A_1}{\sigma(C_2)}, H')$
is returned, where $H'$ is the list of all assumptions made in $H_1$, $H_2$
and by the procedure $P$.


\item Automatically time align {\tt AUTOTIME  P Thm1  Thm2 g} 

Type: {\tt proof\_type->Theorem->Theorem->Theorem}

Many proofs contain a step in which a user time shifts
one result and then uses the time shifted result as one
of the arguments to the {\tt TRANS} rule. The {\tt AUTOTIME}
rule tries to make this easier by automatically coming
up with the appropriate time shift.

{\tt AUTOTIME} rule takes a proof procedure $P$, and two theorems 
$(\Assert{A_1}{C_1}, H_1)$ and $(\Assert{A_2}{C_2}, H_2)$.
It applies a heuristic to these theorems to find a time shift $t$
by which one of the theorems must be shifted. Recall from the
theory that time shifts can only be forward in time. If $t \geq 0$
then the consequent is shifted forwards by $t$. If $t < 0$, the
antecedent is shifted forwards by $-t$. If $t \geq 0$ the rule
then checks whether $\delta_{\N^tA'_2}
\order {\delta_{A_1}}\sqcup{\delta_{C_1}}$ (it may use
the theory $T$ for this). If the comparison succeeds
then the theorem $(\Assert{A_1}{\sigma(C_2)}, H')$
is returned where $H'$ is the list of all assumptions made in $H_1$, $H_2$
and by the procedure $P$. The case of $t < 0$ is treated similarly.

\item Automatic time align and specialise:
{\tt ALIGNSUB  theory Thm1 Thm2}

Type: {\tt proof\_type->Theorem->Theorem->Theorem}

This is similar to the {\tt AUTOTIME} rule, but not only does
it find a time shift, but it also tries to find a specialisation
for the second theorem.


\item Debug information: {\tt Explore flags varorder Ant tracelist}

Type: {\tt string->(bool list)->traj\_tp->(string\#int\#int list)->bool}

This is not an inference rule, but an interface to Voss's debugging
facilities.


\end{enumerate}

\subsection{Mapping information}

There are some types of queries which while they can't be
expressed directly as trajectory formulas can be checked for
quite easily. By introducing extra variables into the
consequent we are able to extract more information from
the circuit and find out more about its behaviour.

Where there are variables which appear in the consequent
which do not appear in the antecedent, trajectory evaluation
only succeeds when there is a certain relation between the
variables in the antecedent and the variables in the
consequent.

A theorem, represented by the triple $(\Assert{A}{C},\,H,f)$
says that:
\begin{itemize}
\item
Assuming the assumptions in  $H$,
\item
For every interpretation of variables in the antecedent
there is a consistent interpretation of the variables
in the consequent such that,
\item
The trajectory evaluaton succeeds, and
\item
For such interpretations the boolean expression $f$ is
satisfied.
\end{itemize}

\noindent
Let's look at an example. 

\begin{example}
\rm
Consider the carry save adder shown in Figure~\ref{csafig}.
We wish to show that if at time 0 the sum of the three
input lines is $x$ then at time $n$ the sum of the two output
lines is also $n$. In this case we choose as the antecedent
$$(A \is a) \vand (B \is b) \vand (C \is c) \from 0 \vto n$$ and
as consequent
$$(D \is d) \vand (E \is e) \from n \vto n+1$$ and as {\em cond}
$$a+b+c=d+e$$

{\tt COND\_VOSS varmap (Ant, Con) cond}
\end{example}



\LFIG{csa}{Carry-save adder}{csafig}



\noindent
There are two rules which explicitly deal with the mapping
information. These are described below as well as a brief description
of how the inference rules above are affected by mapping information.

\begin{enumerate}




\item
Conditional STE: {\tt COND\_VOSS varmap (Ant,  Con) f}

Type: {\tt (bool list)->(traj\_tp\#traj\_tp)->B->Theorem}

There are three arguments: a BDD variable ordering; an
antecedent, consequent pair; and a boolean expression
The COND\_VOSS rule is similar to the VOSS rule. However, 
the consequent may use variables which do not appear in the 
antecedent. The COND\_VOSS rule checks that for every
interpretation of variables in the antecedent there is an
a consistent interpretation of variables in the consequent 
for which trajectory evaluation succeeds, {\em and} that
for every such interpretation of variables, the boolean
expression $f$ is satisfied.


  
\item Weaken implication: {\tt WEAKENIMP trans thm}

Type: {\tt (B->B)->Theorem->Theorem}

Takes a transformation function and a theorem $(G, H, f)$.
{\it trans} (of type {\tt B->B}). Is a function which must
satisfy $g = \mbox{\it trans}(f)$ iff $f \Rightarrow g$.
Essentially {\it trans} is a rewrite rule. It then rewrites
the expression $f$ to $g$ and returns as a theore $(G, H, g)$.
(Since we know that $G$ implies that the condition $f$ is
true, if $f \Rightarrow g$, then $G$ implies that $g$ is true).



\end{enumerate}

\subsection{Running the system}

\subsubsection{Configuration file}

A configuration file must  be set up by the user.


\begin{enumerate}

\item
The library file {\tt library.fl} must be loaded.

\item
The variable {\tt path\_name} must be set to the path name 
(relative to current working directory) where the system can
be found.

\item
The variable {\tt bit\_width} must be set to a positive integer.

\item
{\tt circuit\_fsm} must be set to the fsm of the circuit
being executed. This may be done by using ``load\_exe'' or
using the EXE library.

\item
{\tt circuit\_map\_list} should be set to map the correspondence
between node names used in the specification, and the node names
as they appear in the physical circuit. This is most useful
for higher domain names in the specification which map to 
multiple nodes in the physical circuit. {\tt circuit\_map\_list}
is of type {\tt ((string \# (string list)) list)}. The first
component is the name of the node in the specification, the
second component is the list of names which will be substituted
for the specification name.

The routine {\tt arraylist} may be useful in this. It takes
a string {\it name} and two integers --- a start index $s$ and
the number of elements to be generated $n$, and returns the
list $name[s], \ldots, name[s+n-1]$. 
The routine {\tt listlist} takes
a string $N$ and two integers --- a start index $s$ and
the number of elements to be generated $n$, and returns the
list $N_s, \ldots, N_{s+n-1}$.

There are some other routines
in ``library.fl'' which may be useful and may be documented some time.


As an example, the following code 

\begin{verbatim}

let circuit_map_list =
       [("A", rev(arraylist "ainp" 1 bit_width)),
        ("B", rev(arraylist "binp" 1 bit_width))]@
        (map (\x.
             ("TC"^(int2str x),rev(arraylist "res" (x*bit_width+1) bit_width)))
             (gen (bit_width+1)));

\end{verbatim}

produces the following mapping, assuming {\it bit\_width} has the value 4:

\begin{verbatim}

[(``A'',[``ainp[4]'', ``ainp[3]'', ``ainp[2]'', ``ainp[1]'']),
 (``B'',[``binp[4]'', ``binp[3]'', ``binp[2]'', ``binp[1]'']),
 (``TC0'',[``res[4]'', ``res[3]'', ``res[2]'', ``res[1]'']),
 .....
 (``TC5'',[``res[24]'',''res[23]'',''res[22]'',''res[21]''])]

\end{verbatim}

When the circuit is verified, any specification which refers
to ``A'' will get translated so that the appropriate values
refer to the values of the nodes ``ainp[1]'', \ldots, ``ainp[4]''.


\item
The library file {\tt init.fl} file must be loaded.


\end{enumerate}

Finally load your proof script file and prove away \ldots

